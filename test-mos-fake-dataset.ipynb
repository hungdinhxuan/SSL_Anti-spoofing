{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "\n",
    "device = 'cuda:3'\n",
    "model = Model(None, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa.display\n",
    "import os\n",
    "\n",
    "def load_audio(path):\n",
    "    audio, sample_rate = torchaudio.load(path)\n",
    "    return audio\n",
    "\n",
    "\n",
    "DATA_PATH = './VCTK-synthesis-test-2_best'\n",
    "audios = [load_audio(os.path.join(DATA_PATH, file)) for file in os.listdir(DATA_PATH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (ssl_model): SSLModel(\n",
       "    (model): Wav2Vec2Model(\n",
       "      (feature_extractor): ConvFeatureExtractionModel(\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Sequential(\n",
       "              (0): TransposeLast()\n",
       "              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): TransposeLast()\n",
       "            )\n",
       "            (3): GELU()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Sequential(\n",
       "              (0): TransposeLast()\n",
       "              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): TransposeLast()\n",
       "            )\n",
       "            (3): GELU()\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Sequential(\n",
       "              (0): TransposeLast()\n",
       "              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): TransposeLast()\n",
       "            )\n",
       "            (3): GELU()\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Sequential(\n",
       "              (0): TransposeLast()\n",
       "              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): TransposeLast()\n",
       "            )\n",
       "            (3): GELU()\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Sequential(\n",
       "              (0): TransposeLast()\n",
       "              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): TransposeLast()\n",
       "            )\n",
       "            (3): GELU()\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Sequential(\n",
       "              (0): TransposeLast()\n",
       "              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): TransposeLast()\n",
       "            )\n",
       "            (3): GELU()\n",
       "          )\n",
       "          (6): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Sequential(\n",
       "              (0): TransposeLast()\n",
       "              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): TransposeLast()\n",
       "            )\n",
       "            (3): GELU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_extract_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (dropout_input): Dropout(p=0.0, inplace=False)\n",
       "      (dropout_features): Dropout(p=0.0, inplace=False)\n",
       "      (quantizer): GumbelVectorQuantizer(\n",
       "        (weight_proj): Linear(in_features=512, out_features=640, bias=True)\n",
       "      )\n",
       "      (project_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (encoder): TransformerEncoder(\n",
       "        (pos_conv): Sequential(\n",
       "          (0): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "          (1): SamePad()\n",
       "          (2): GELU()\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (12): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (13): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (14): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (15): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (16): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (17): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (18): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (19): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (20): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (21): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (22): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (23): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (final_proj): Linear(in_features=1024, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (LL): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (first_bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (first_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.5, inplace=True)\n",
       "  (drop_way): Dropout(p=0.2, inplace=True)\n",
       "  (selu): SELU(inplace=True)\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (conv1): Conv2d(1, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (conv_downsample): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        (conv_downsample): Conv2d(32, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Residual_block(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (selu): SELU(inplace=True)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attention): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): SELU(inplace=True)\n",
       "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (GAT_layer_S): GraphAttentionLayer(\n",
       "    (att_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (proj_with_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (proj_without_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (GAT_layer_T): GraphAttentionLayer(\n",
       "    (att_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (proj_with_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (proj_without_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST11): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (proj_type2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (att_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST12): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST21): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (proj_type2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (att_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (HtrgGAT_layer_ST22): HtrgGraphAttentionLayer(\n",
       "    (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input_drop): Dropout(p=0.2, inplace=False)\n",
       "    (act): SELU(inplace=True)\n",
       "  )\n",
       "  (pool_S): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_T): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hS1): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hT1): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hS2): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (pool_hT2): GraphPool(\n",
       "    (sigmoid): Sigmoid()\n",
       "    (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (drop): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (out_layer): Linear(in_features=160, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = load_audio('common_voice_en_1164.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3755, 0.6245]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "output = model(audio)\n",
    "probabilities = F.softmax(output, dim=1)\n",
    "print(probabilities)\n",
    "predicted_class = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchaudio  # Assuming torchaudio is used for audio file loading\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Sort the batch in the descending order of audio lengths\n",
    "    batch.sort(key=lambda x: x[1], reverse=True)\n",
    "    sequences, lengths, filenames = zip(*batch)\n",
    "\n",
    "    # Pad the sequences to have equal length\n",
    "    sequences_padded = pad_sequence(sequences, batch_first=True)\n",
    "    \n",
    "    # Debugging: print shapes\n",
    "    print(\"Shapes before padding:\", [s.shape for s in sequences])\n",
    "    print(\"Shape after padding:\", sequences_padded.shape)\n",
    "\n",
    "    return sequences_padded, filenames\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.filenames = [f for f in os.listdir(directory) if f.endswith('.wav')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = os.path.join(self.directory, self.filenames[idx])\n",
    "        waveform, _ = torchaudio.load(filepath)  # Load waveform\n",
    "        return waveform, waveform.size(1), self.filenames[idx]\n",
    "        \n",
    "def produce_evaluation_file(dataset, model, device, save_path):\n",
    "    data_loader = DataLoader(dataset, batch_size=14, shuffle=False, drop_last=False, collate_fn=collate_fn)\n",
    "    model.eval()\n",
    "\n",
    "    for batch_x, utt_id in data_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_out = model(batch_x)  # Modify as per your model's requirements\n",
    "        \n",
    "        # Assuming batch_out is the score or output you want to evaluate\n",
    "        batch_score = batch_out.data.cpu().numpy().ravel()\n",
    "        \n",
    "        with open(save_path, 'a+') as fh:\n",
    "            for f, score in zip(utt_id, batch_score):\n",
    "                fh.write('{} {}\\n'.format(f, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from model import Model\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'                  \n",
    "eval_output='eval_pre_trained_model_CM_scores_file_SSL_DF.txt'\n",
    "model_path='./Best_LA_model_for_DF.pth'\n",
    "\n",
    "model = Model(None, device=device)\n",
    "model =nn.DataParallel(model).to(device)\n",
    "database_path = './VCTK-synthesis-test-2_best'\n",
    "model.load_state_dict(torch.load(model_path,map_location=device))\n",
    "\n",
    "\n",
    "print('Device: {}'.format(device))\n",
    "print('Model loaded : {}'.format(model_path))\n",
    "\n",
    "custom_dataset = CustomDataset(directory=database_path)\n",
    "produce_evaluation_file(custom_dataset, model, device, eval_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "nb_params: 317837834\n",
      "Model loaded : ./Best_LA_model_for_DF.pth\n",
      "no. of eval trials 611829\n",
      "/home/hungdx/miniconda3/envs/SSL_Spoofing/lib/python3.7/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hungdx/miniconda3/envs/SSL_Spoofing/lib/python3.7/site-packages/librosa/core/audio.py\", line 155, in load\n",
      "    context = sf.SoundFile(path)\n",
      "  File \"/home/hungdx/miniconda3/envs/SSL_Spoofing/lib/python3.7/site-packages/soundfile.py\", line 658, in __init__\n",
      "    self._file = self._open(file, mode_int, closefd)\n",
      "  File \"/home/hungdx/miniconda3/envs/SSL_Spoofing/lib/python3.7/site-packages/soundfile.py\", line 1216, in _open\n",
      "    raise LibsndfileError(err, prefix=\"Error opening {0!r}: \".format(self.name))\n",
      "soundfile.LibsndfileError: Error opening './VCTK-synthesis-test-2_bestASVspoof2021_DF_eval/flac/DF_E_2000011.flac': System error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"main_SSL_DF.py\", line 256, in <module>\n",
      "    produce_evaluation_file(eval_set, model, device, args.eval_output)\n",
      "  File \"main_SSL_DF.py\", line 53, in produce_evaluation_file\n",
      "    for batch_x,utt_id in data_loader:\n",
      "  File \"/home/hungdx/miniconda3/envs/SSL_Spoofing/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/hungdx/miniconda3/envs/SSL_Spoofing/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 557, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/home/hungdx/miniconda3/envs/SSL_Spoofing/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/hungdx/miniconda3/envs/SSL_Spoofing/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/nfs/datab/hungdx/SSL_Anti-spoofing/data_utils_SSL.py\", line 101, in __getitem__\n",
      "    X, fs = librosa.load(self.base_dir+'flac/'+utt_id+'.flac', sr=16000)\n",
      "  File \"/home/hungdx/miniconda3/envs/SSL_Spoofing/lib/python3.7/site-packages/librosa/util/decorators.py\", line 88, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/hungdx/miniconda3/envs/SSL_Spoofing/lib/python3.7/site-packages/librosa/core/audio.py\", line 174, in load\n",
      "    y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "  File \"/home/hungdx/miniconda3/envs/SSL_Spoofing/lib/python3.7/site-packages/librosa/core/audio.py\", line 198, in __audioread_load\n",
      "    with audioread.audio_open(path) as input_file:\n",
      "  File \"/home/hungdx/miniconda3/envs/SSL_Spoofing/lib/python3.7/site-packages/audioread/__init__.py\", line 127, in audio_open\n",
      "    return BackendClass(path)\n",
      "  File \"/home/hungdx/miniconda3/envs/SSL_Spoofing/lib/python3.7/site-packages/audioread/rawread.py\", line 59, in __init__\n",
      "    self._fh = open(filename, 'rb')\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './VCTK-synthesis-test-2_bestASVspoof2021_DF_eval/flac/DF_E_2000011.flac'\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python main_SSL_DF.py --track=DF --is_eval --eval --model_path='./Best_LA_model_for_DF.pth' --eval_output='eval_pre_trained_model_CM_scores_file_SSL_DF.txt' --database_path='./VCTK-synthesis-test-2_best' --batch_size=256 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSL_Spoofing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
