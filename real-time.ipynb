{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set CUDA_VISIBLE_DEVICES to an empty string to hide all GPUs\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "# Load audio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa.display\n",
    "from model import Model\n",
    "from torch import nn\n",
    "\n",
    "def load_audio(path):\n",
    "    audio, sample_rate = torchaudio.load(path)\n",
    "    return audio, sample_rate\n",
    "\n",
    "device = 'cpu'\n",
    "model_path = './Best_LA_model_for_DF.pth'\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'                  \n",
    "print('Device: {}'.format(device))\n",
    "# audio, sample_rate = load_audio('./common_voice_en_1164.wav')\n",
    "model = Model(None, device=device).to(device)\n",
    "nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "# model =nn.DataParallel(model).to(device)\n",
    "print('nb_params:',nb_params)\n",
    "model.load_state_dict(torch.load(model_path,map_location=device), strict=False)\n",
    "print('Model loaded : {}'.format(model_path))\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from data_utils_SSL import pad\n",
    "from torch import Tensor\n",
    "import librosa\n",
    "import psutil\n",
    "\n",
    "\n",
    "audio,_ = librosa.load('/datab/hungdx/SSL_Anti-spoofing/commonvoice/test/clips/common_voice_en_19698109.wav', sr=16000)\n",
    "\n",
    "def get_system_usage():\n",
    "    cpu_usage = psutil.cpu_percent(interval=1)  # CPU usage over 1 second\n",
    "    gpu_usage = None\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()  # Synchronize CPU and GPU\n",
    "        gpu_usage = torch.cuda.max_memory_allocated()  # Get max GPU memory allocated\n",
    "        torch.cuda.reset_max_memory_allocated()  # Reset the max memory allocated counter\n",
    "    return cpu_usage, gpu_usage\n",
    "\n",
    "def detect_deepfake(audio_data, model, segment_duration=4.0, sampling_rate=16000):\n",
    "    segment_length = int(segment_duration * sampling_rate)\n",
    "    total_segments = len(audio_data) // segment_length\n",
    "    predictions = []\n",
    "    latencies = []\n",
    "    system_usages = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(total_segments):\n",
    "            segment = audio_data[i * segment_length:(i + 1) * segment_length]\n",
    "            segment = pad(segment, 64600)\n",
    "            segment = Tensor(segment).unsqueeze(0).to(device)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            out = model(segment)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            output_probs = torch.sigmoid(out)\n",
    "            predictions.append(output_probs)\n",
    "            \n",
    "            latency = (end_time - start_time) * 1000\n",
    "            latencies.append(latency)\n",
    "            \n",
    "            # Get system usage\n",
    "            cpu_usage, gpu_usage = get_system_usage()\n",
    "            system_usages.append((cpu_usage, gpu_usage))\n",
    "        \n",
    "    return predictions, latencies, system_usages\n",
    "\n",
    "# Run the deepfake detection simulation\n",
    "predictions, latencies, system_usages,  = detect_deepfake(audio, model)\n",
    "\n",
    "# Output the predictions and latencies\n",
    "# Output the predictions, latencies, and system usages\n",
    "for i, (pred, latency, (cpu_usage, gpu_usage)) in enumerate(zip(predictions, latencies, system_usages)):\n",
    "    fake_prob = round(float(pred[0][1]) * 100, 2)\n",
    "    # Convert GPU usage from bytes to megabytes\n",
    "    gpu_usage = round(float(gpu_usage) / 1024 / 1024, 2)\n",
    "    print(f\"Segment {i+1}: Prediction - Fake({fake_prob}%), Inference time - {latency:.2f} ms, CPU usage - {cpu_usage}%, GPU usage - {gpu_usage} megabytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random a fake audio 30s \n",
    "fake_audio = np.random.rand(30 * 16000)\n",
    "\n",
    "# Run the deepfake detection simulation\n",
    "predictions, avg_cpu_usage, avg_gpu_usage, avg_latency = detect_deepfake(fake_audio, model)\n",
    "\n",
    "# Output the averages\n",
    "print(f\"Average CPU Usage: {avg_cpu_usage:.2f}%\")\n",
    "print(f\"Average GPU Usage: {avg_gpu_usage:.2f} GB\")\n",
    "print(f\"Average Inference Time: {avg_latency:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8s fake audio\n",
    "fake_audio_jp = librosa.load('/datab/hungdx/conformer-based-classifier-for-anti-spoofing/000126_SeamlessM4T-TTS_jpn.wav', sr=16000)\n",
    "\n",
    "# Repeat audio 500 times\n",
    "fake_audio2 = np.tile(fake_audio_jp[0], 500)\n",
    "\n",
    "predictions, avg_cpu_usage, avg_gpu_usage, avg_latency = detect_deepfake(fake_audio2, model)\n",
    "\n",
    "# Output the averages\n",
    "print(f\"Average CPU Usage: {avg_cpu_usage:.2f}%\")\n",
    "print(f\"Average GPU Usage: {avg_gpu_usage:.2f} GB\")\n",
    "print(f\"Average Inference Time: {avg_latency:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVG inference time: 42 ms, Memory: 8GB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
